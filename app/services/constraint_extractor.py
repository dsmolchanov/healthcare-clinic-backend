"""
Constraint Extraction Service
Extracts conversation constraints from user messages using keyword detection + LLM
"""

from typing import Optional, Tuple, List, Dict, Any
import re
from datetime import datetime, timedelta
import json
import logging

logger = logging.getLogger(__name__)


class ConstraintExtractor:
    """Extracts constraints from user messages"""

    # Meta-command patterns for complete context reset
    META_RESET_PATTERNS = {
        'ru': [
            '–∑–∞–±—É–¥—å –≤—Å—ë', '–∑–∞–±—É–¥—å –≤—Å–µ',  # Both —ë and –µ variants
            '–∑–∞–±—É–¥—å –ø—Ä–æ –≤—Å—ë', '–∑–∞–±—É–¥—å –ø—Ä–æ –≤—Å–µ',  # Both —ë and –µ variants
            'previous intents', '–Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ', '—Å–±—Ä–æ—Å–∏—Ç—å', '–Ω–∞—á–Ω–∏ —Å–Ω–∞—á–∞–ª–∞'
        ],
        'en': ['forget everything', 'start over', 'reset', 'previous intents', 'clear context', 'start fresh'],
        'es': ['olvida todo', 'empezar de nuevo', 'resetear', 'borrar todo'],
        'he': ['◊©◊õ◊ó ◊î◊õ◊ú', '◊î◊™◊ó◊ú ◊û◊ó◊ì◊©', '◊ê◊ô◊§◊ï◊°']
    }

    # Keyword patterns for negations/exclusions
    FORGET_KEYWORDS = {
        'ru': ['–∑–∞–±—É–¥—å', '–∑–∞–±—É–¥—å—Ç–µ', '–Ω–µ –Ω—É–∂–µ–Ω', '–Ω–µ –Ω–∞–¥–æ', '–Ω–µ —Ö–æ—á—É'],
        'en': ['forget', 'don\'t need', 'don\'t want', 'not interested'],
        'es': ['olvida', 'no necesito', 'no quiero'],
        'he': ['◊©◊õ◊ó', '◊ú◊ê ◊¶◊®◊ô◊ö', '◊ú◊ê ◊®◊ï◊¶◊î']
    }

    # Blacklist of sentence words that indicate extraction failure
    SENTENCE_FRAGMENT_WORDS = {
        'ru': ['—Å–ø–∏—Å–∫–µ', '–≤—Ä–∞—á–µ–π', '—Å–∫–∞–∑–∞–ª', '—Å–∫–∞–∑–∞–ª–∞', '–∑–∞–ø–∏—Å–∞—Ç—å', '–Ω–∞—à–ª–∏', '–≤—ã–¥–∞–ª–∏',
               '–ø–æ–ø—Ä–æ—Å–∏–ª', '–ø–æ–ø—Ä–æ—Å–∏–ª–∞', '–∫–æ—Ç–æ—Ä–æ–≥–æ', '–∫–æ—Ç–æ—Ä—É—é', '–ø–æ—Ç–æ–º', '–ø–æ—Å–ª–µ'],
        'en': ['list', 'said', 'told', 'asked', 'found', 'showed', 'doctor', 'doctors',
               'which', 'whom', 'that', 'then', 'after'],
        'es': ['lista', 'dijo', 'pregunt√≥', 'encontr√≥', 'mostr√≥', 'm√©dico', 'm√©dicos',
               'cual', 'quien', 'entonces', 'despu√©s'],
        'he': ['◊®◊©◊ô◊û◊î', '◊ê◊û◊®', '◊ê◊û◊®◊î', '◊ë◊ô◊ß◊©', '◊û◊¶◊ê', '◊î◊®◊ê◊î', '◊®◊ï◊§◊ê', '◊®◊ï◊§◊ê◊ô◊ù']
    }

    SWITCH_KEYWORDS = {
        'ru': ['–≤–º–µ—Å—Ç–æ', '–ª—É—á—à–µ', '—Ö–æ—á—É', '–¥–∞–≤–∞–π—Ç–µ', '–ø–µ—Ä–µ–∫–ª—é—á–∏–º—Å—è'],
        'en': ['instead', 'rather', 'want', 'let\'s switch'],
        'es': ['en lugar de', 'prefiero', 'quiero'],
        'he': ['◊ë◊û◊ß◊ï◊ù', '◊¢◊ì◊ô◊£', '◊®◊ï◊¶◊î']
    }

    # Time-related keywords for extraction
    TOMORROW_KEYWORDS = ['–∑–∞–≤—Ç—Ä–∞', 'tomorrow', 'ma√±ana', '◊û◊ó◊®']
    TODAY_KEYWORDS = ['—Å–µ–≥–æ–¥–Ω—è', 'today', 'hoy', '◊î◊ô◊ï◊ù']

    # Time extraction patterns (captures hour)
    TIME_PATTERNS = [
        r'(\d{1,2})\s*(?:—É—Ç—Ä–∞|am|—á–∞—Å–æ–≤?|—á\.?)',  # 11 —É—Ç—Ä–∞, 11am, 11 —á–∞—Å–æ–≤
        r'–≤\s*(\d{1,2})(?:\s|$|,|\.|:)',  # –≤ 11
        r'–Ω–∞\s*(\d{1,2})(?:\s|$|,|\.)',  # –Ω–∞ 11
        r'at\s*(\d{1,2})',  # at 11
        r'^(\d{1,2})$',  # Just "11" alone
        r',\s*(\d{1,2})(?:\s|$)',  # "–ó–∞–≤—Ç—Ä–∞, 11"
    ]

    def detect_meta_reset(self, message: str, language: str = 'ru') -> bool:
        """
        Detect if user wants to reset conversation context entirely.

        This is for meta-commands like "forget everything" or "previous intents"
        that should trigger a complete context reset, not just entity exclusion.

        Returns:
            True if meta-reset pattern detected, False otherwise
        """
        message_lower = message.lower()
        patterns = self.META_RESET_PATTERNS.get(language, self.META_RESET_PATTERNS['en'])

        for pattern in patterns:
            if pattern in message_lower:
                logger.info(f"üîÑ Meta-reset detected: '{pattern}' in message")
                return True

        return False

    def detect_forget_pattern(self, message: str, language: str = 'ru') -> Optional[List[str]]:
        """
        Detect 'Forget about X' patterns with validation.

        Returns:
            List of entities to exclude (e.g., ["Dan", "–ø–ª–æ–º–±–∞"])
        """
        message_lower = message.lower()
        keywords = self.FORGET_KEYWORDS.get(language, self.FORGET_KEYWORDS['en'])

        entities_to_exclude = []

        for keyword in keywords:
            if keyword in message_lower:
                # Extract what comes after the keyword - TIGHTENED with length limit
                pattern = rf'{keyword}\s+(–ø—Ä–æ\s+)?([–∞-—è—ëa-z\s]{{3,25}}?)(?:\s+–∏\s+|\s*$|[.,!?])'
                matches = re.findall(pattern, message_lower, re.IGNORECASE)

                for match in matches:
                    entity = match[-1].strip()
                    if entity and self._validate_extracted_constraint(entity, language):
                        entities_to_exclude.append(entity)
                    elif entity:
                        logger.warning(f"üö´ Invalid entity in forget pattern: '{entity}'")

        return entities_to_exclude if entities_to_exclude else None

    def _validate_extracted_constraint(self, entity: str, language: str = 'ru') -> bool:
        """
        Validate extracted constraint to prevent garbage extraction.

        Returns True if entity is valid, False if it's garbage/sentence fragment.

        Validation layers:
        1. Length check (>50 chars ‚Üí reject)
        2. Word count (>4 words ‚Üí reject)
        3. Sentence fragment detection (contains blacklist words ‚Üí reject)
        4. Verb detection (ends in verb suffixes ‚Üí reject)
        """
        if not entity or not isinstance(entity, str):
            return False

        entity = entity.strip()

        # Layer 1: Length check
        if len(entity) > 50:
            logger.warning(f"üö´ Rejected constraint (too long): '{entity[:50]}...'")
            return False

        # Layer 2: Word count
        words = entity.split()
        if len(words) > 4:
            logger.warning(f"üö´ Rejected constraint (too many words): '{entity}'")
            return False

        # Layer 3: Sentence fragment detection
        blacklist = self.SENTENCE_FRAGMENT_WORDS.get(language, self.SENTENCE_FRAGMENT_WORDS['en'])
        entity_lower = entity.lower()
        for blacklist_word in blacklist:
            if blacklist_word in entity_lower:
                logger.warning(f"üö´ Rejected constraint (contains '{blacklist_word}'): '{entity}'")
                return False

        # Layer 4: Verb detection (Russian-specific)
        if language == 'ru':
            # Check for verb endings (past tense, infinitive)
            if any(entity_lower.endswith(suffix) for suffix in ['–ª–∏', '–ª–∞', '–ª–æ', '—Ç—å', '—Ç–∏', '—á—å']):
                logger.warning(f"üö´ Rejected constraint (verb detected): '{entity}'")
                return False

        return True

    def detect_switch_pattern(self, message: str, language: str = 'ru') -> Optional[Tuple[str, str]]:
        """
        Detect 'Instead of X, I want Y' patterns with validation.

        Returns:
            Tuple of (exclude_entity, desired_entity) or None
        """
        message_lower = message.lower()

        # Tightened patterns with length limits to prevent sentence capture
        # Pattern 1: Explicit "instead of" switch
        patterns = [
            r'–≤–º–µ—Å—Ç–æ\s+([–∞-—è—ë\s]{3,25}?)\s+(?:—Ö–æ—á—É|–∂–µ–ª–∞—é|–Ω—É–∂–Ω[–æ–∞])\s+([–∞-—è—ë\s]{3,25}?)(?:\s*$|[.,!?])',
            # Pattern 2: "not X, but Y" - MORE RESTRICTIVE (shorter capture, Cyrillic only)
            r'–Ω–µ\s+([–∞-—è—ë\s]{3,20}?),?\s+–∞\s+([–∞-—è—ë\s]{3,20}?)(?:\s*$|[.,!?])',
            # Pattern 3: English
            r'instead of\s+([a-z\s]{3,25}?),?\s+(?:I want|prefer)\s+([a-z\s]{3,25}?)(?:\s*$|[.,!?])'
        ]

        for pattern in patterns:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                exclude_entity = match.group(1).strip()
                desired_entity = match.group(2).strip()

                # CRITICAL: Validate both entities before returning
                if not self._validate_extracted_constraint(exclude_entity, language):
                    logger.warning(f"üö´ Invalid exclude entity in switch: '{exclude_entity}'")
                    continue

                if not self._validate_extracted_constraint(desired_entity, language):
                    logger.warning(f"üö´ Invalid desired entity in switch: '{desired_entity}'")
                    continue

                # Both entities passed validation
                return (exclude_entity, desired_entity)

        return None

    def extract_date_time(self, message: str, reference_date: datetime, language: str = 'ru') -> Optional[Dict[str, Any]]:
        """
        Extract date and time from user message.

        Args:
            message: User message like "–ó–∞–≤—Ç—Ä–∞, 11" or "ma√±ana a las 10"
            reference_date: Current date for calculation
            language: Language code

        Returns:
            Dict with:
            - date: "2025-12-19" (ISO format)
            - time: "11:00" or None
            - display: "–∑–∞–≤—Ç—Ä–∞ –≤ 11:00"
        """
        message_lower = message.lower().strip()
        result = {'date': None, 'time': None, 'display': None}

        # Extract date
        if any(kw in message_lower for kw in self.TOMORROW_KEYWORDS):
            target_date = reference_date + timedelta(days=1)
            result['date'] = target_date.strftime('%Y-%m-%d')
            result['display'] = '–∑–∞–≤—Ç—Ä–∞' if language == 'ru' else 'tomorrow'
        elif any(kw in message_lower for kw in self.TODAY_KEYWORDS):
            result['date'] = reference_date.strftime('%Y-%m-%d')
            result['display'] = '—Å–µ–≥–æ–¥–Ω—è' if language == 'ru' else 'today'

        # Extract time
        for pattern in self.TIME_PATTERNS:
            match = re.search(pattern, message_lower)
            if match:
                hour = int(match.group(1))
                if 0 <= hour <= 23:
                    # Assume AM for hours 6-11 if no AM/PM specified
                    result['time'] = f"{hour:02d}:00"
                    if result['display']:
                        result['display'] += f" –≤ {hour}:00" if language == 'ru' else f" at {hour}:00"
                    else:
                        result['display'] = f"{hour}:00"
                    break

        # Return None if nothing was extracted
        if result['date'] is None and result['time'] is None:
            return None

        logger.info(f"üìÖ Extracted date/time from '{message}': {result}")
        return result

    def normalize_time_window(self, time_expression: str, reference_date: datetime, language: str = 'ru') -> Optional[Tuple[str, str, str]]:
        """
        Normalize relative time expressions to absolute dates.

        Args:
            time_expression: "—Å–ª–µ–¥—É—é—â–∞—è –Ω–µ–¥–µ–ª—è", "next week", etc.
            reference_date: Current date for calculation
            language: Language code

        Returns:
            Tuple of (start_date_iso, end_date_iso, display_str) or None
        """
        time_lower = time_expression.lower()

        # Detect "next week"
        next_week_keywords = {
            'ru': ['—Å–ª–µ–¥—É—é—â–∞—è –Ω–µ–¥–µ–ª—è', '—Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ', '–Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ'],
            'en': ['next week'],
            'es': ['la pr√≥xima semana', 'pr√≥xima semana'],
            'he': ['◊©◊ë◊ï◊¢ ◊î◊ë◊ê']
        }

        keywords = next_week_keywords.get(language, next_week_keywords['en'])

        for keyword in keywords:
            if keyword in time_lower:
                # Calculate next Monday-Sunday
                days_until_monday = (7 - reference_date.weekday()) % 7
                if days_until_monday == 0:
                    days_until_monday = 7  # If today is Monday, next week starts in 7 days

                start_date = reference_date + timedelta(days=days_until_monday)
                end_date = start_date + timedelta(days=6)

                # Format display string based on language
                if language == 'ru':
                    display = f"{start_date.day}‚Äì{end_date.day} {self._month_name_ru(end_date.month)}"
                else:
                    display = f"{start_date.strftime('%d')}‚Äì{end_date.strftime('%d %B')}"

                return (
                    start_date.date().isoformat(),
                    end_date.date().isoformat(),
                    display
                )

        return None

    def _month_name_ru(self, month: int) -> str:
        """Get Russian month name (genitive case for date ranges)"""
        months = {
            1: "—è–Ω–≤–∞—Ä—è", 2: "—Ñ–µ–≤—Ä–∞–ª—è", 3: "–º–∞—Ä—Ç–∞", 4: "–∞–ø—Ä–µ–ª—è",
            5: "–º–∞—è", 6: "–∏—é–Ω—è", 7: "–∏—é–ª—è", 8: "–∞–≤–≥—É—Å—Ç–∞",
            9: "—Å–µ–Ω—Ç—è–±—Ä—è", 10: "–æ–∫—Ç—è–±—Ä—è", 11: "–Ω–æ—è–±—Ä—è", 12: "–¥–µ–∫–∞–±—Ä—è"
        }
        return months.get(month, "")

    async def extract_with_llm(
        self,
        message: str,
        conversation_history: List[Dict],
        llm_client
    ) -> Dict[str, Any]:
        """
        Use LLM to extract constraints when keyword matching insufficient.

        Returns dict with:
            - desired_service: str | None
            - desired_doctor: str | None
            - excluded_doctors: List[str]
            - excluded_services: List[str]
            - confidence: float (0-1)
        """

        prompt = f"""Extract conversation constraints from this message.

Message: "{message}"

Recent conversation:
{json.dumps(conversation_history[-3:], indent=2, ensure_ascii=False)}

Extract:
1. What service does the user want? (e.g., "veneers", "cleaning")
2. What doctor do they want? (e.g., "Andrea", "Dr. Smith")
3. What doctors should be EXCLUDED? (e.g., user said "forget about Dan")
4. What services should be EXCLUDED? (e.g., user said "not fillings")

Respond ONLY with JSON:
{{
  "desired_service": "service name or null",
  "desired_doctor": "doctor name or null",
  "excluded_doctors": ["doctor1", "doctor2"],
  "excluded_services": ["service1", "service2"],
  "confidence": 0.95
}}
"""

        try:
            response = await llm_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=200
            )

            result = json.loads(response.choices[0].message.content)
            return result
        except Exception as e:
            logger.error(f"LLM constraint extraction failed: {e}")
            return {
                "desired_service": None,
                "desired_doctor": None,
                "excluded_doctors": [],
                "excluded_services": [],
                "confidence": 0.0
            }
