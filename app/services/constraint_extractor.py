"""
Constraint Extraction Service
Extracts conversation constraints from user messages using keyword detection + LLM
"""

from typing import Optional, Tuple, List, Dict, Any
import re
from datetime import datetime, timedelta
import json
import logging

logger = logging.getLogger(__name__)


class ConstraintExtractor:
    """Extracts constraints from user messages"""

    # Keyword patterns for negations/exclusions
    FORGET_KEYWORDS = {
        'ru': ['Ð·Ð°Ð±ÑƒÐ´ÑŒ', 'Ð·Ð°Ð±ÑƒÐ´ÑŒÑ‚Ðµ', 'Ð½Ðµ Ð½ÑƒÐ¶ÐµÐ½', 'Ð½Ðµ Ð½Ð°Ð´Ð¾', 'Ð½Ðµ Ñ…Ð¾Ñ‡Ñƒ'],
        'en': ['forget', 'don\'t need', 'don\'t want', 'not interested'],
        'es': ['olvida', 'no necesito', 'no quiero'],
        'he': ['×©×›×—', '×œ× ×¦×¨×™×š', '×œ× ×¨×•×¦×”']
    }

    # Blacklist of sentence words that indicate extraction failure
    SENTENCE_FRAGMENT_WORDS = {
        'ru': ['ÑÐ¿Ð¸ÑÐºÐµ', 'Ð²Ñ€Ð°Ñ‡ÐµÐ¹', 'ÑÐºÐ°Ð·Ð°Ð»', 'ÑÐºÐ°Ð·Ð°Ð»Ð°', 'Ð·Ð°Ð¿Ð¸ÑÐ°Ñ‚ÑŒ', 'Ð½Ð°ÑˆÐ»Ð¸', 'Ð²Ñ‹Ð´Ð°Ð»Ð¸',
               'Ð¿Ð¾Ð¿Ñ€Ð¾ÑÐ¸Ð»', 'Ð¿Ð¾Ð¿Ñ€Ð¾ÑÐ¸Ð»Ð°', 'ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾', 'ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ', 'Ð¿Ð¾Ñ‚Ð¾Ð¼', 'Ð¿Ð¾ÑÐ»Ðµ'],
        'en': ['list', 'said', 'told', 'asked', 'found', 'showed', 'doctor', 'doctors',
               'which', 'whom', 'that', 'then', 'after'],
        'es': ['lista', 'dijo', 'preguntÃ³', 'encontrÃ³', 'mostrÃ³', 'mÃ©dico', 'mÃ©dicos',
               'cual', 'quien', 'entonces', 'despuÃ©s'],
        'he': ['×¨×©×™×ž×”', '××ž×¨', '××ž×¨×”', '×‘×™×§×©', '×ž×¦×', '×”×¨××”', '×¨×•×¤×', '×¨×•×¤××™×']
    }

    SWITCH_KEYWORDS = {
        'ru': ['Ð²Ð¼ÐµÑÑ‚Ð¾', 'Ð»ÑƒÑ‡ÑˆÐµ', 'Ñ…Ð¾Ñ‡Ñƒ', 'Ð´Ð°Ð²Ð°Ð¹Ñ‚Ðµ', 'Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ð¼ÑÑ'],
        'en': ['instead', 'rather', 'want', 'let\'s switch'],
        'es': ['en lugar de', 'prefiero', 'quiero'],
        'he': ['×‘×ž×§×•×', '×¢×“×™×£', '×¨×•×¦×”']
    }

    def detect_forget_pattern(self, message: str, language: str = 'ru') -> Optional[List[str]]:
        """
        Detect 'Forget about X' patterns with validation.

        Returns:
            List of entities to exclude (e.g., ["Dan", "Ð¿Ð»Ð¾Ð¼Ð±Ð°"])
        """
        message_lower = message.lower()
        keywords = self.FORGET_KEYWORDS.get(language, self.FORGET_KEYWORDS['en'])

        entities_to_exclude = []

        for keyword in keywords:
            if keyword in message_lower:
                # Extract what comes after the keyword - TIGHTENED with length limit
                pattern = rf'{keyword}\s+(Ð¿Ñ€Ð¾\s+)?([Ð°-ÑÑ‘a-z\s]{{3,25}}?)(?:\s+Ð¸\s+|\s*$|[.,!?])'
                matches = re.findall(pattern, message_lower, re.IGNORECASE)

                for match in matches:
                    entity = match[-1].strip()
                    if entity and self._validate_extracted_constraint(entity, language):
                        entities_to_exclude.append(entity)
                    elif entity:
                        logger.warning(f"ðŸš« Invalid entity in forget pattern: '{entity}'")

        return entities_to_exclude if entities_to_exclude else None

    def _validate_extracted_constraint(self, entity: str, language: str = 'ru') -> bool:
        """
        Validate extracted constraint to prevent garbage extraction.

        Returns True if entity is valid, False if it's garbage/sentence fragment.

        Validation layers:
        1. Length check (>50 chars â†’ reject)
        2. Word count (>4 words â†’ reject)
        3. Sentence fragment detection (contains blacklist words â†’ reject)
        4. Verb detection (ends in verb suffixes â†’ reject)
        """
        if not entity or not isinstance(entity, str):
            return False

        entity = entity.strip()

        # Layer 1: Length check
        if len(entity) > 50:
            logger.warning(f"ðŸš« Rejected constraint (too long): '{entity[:50]}...'")
            return False

        # Layer 2: Word count
        words = entity.split()
        if len(words) > 4:
            logger.warning(f"ðŸš« Rejected constraint (too many words): '{entity}'")
            return False

        # Layer 3: Sentence fragment detection
        blacklist = self.SENTENCE_FRAGMENT_WORDS.get(language, self.SENTENCE_FRAGMENT_WORDS['en'])
        entity_lower = entity.lower()
        for blacklist_word in blacklist:
            if blacklist_word in entity_lower:
                logger.warning(f"ðŸš« Rejected constraint (contains '{blacklist_word}'): '{entity}'")
                return False

        # Layer 4: Verb detection (Russian-specific)
        if language == 'ru':
            # Check for verb endings (past tense, infinitive)
            if any(entity_lower.endswith(suffix) for suffix in ['Ð»Ð¸', 'Ð»Ð°', 'Ð»Ð¾', 'Ñ‚ÑŒ', 'Ñ‚Ð¸', 'Ñ‡ÑŒ']):
                logger.warning(f"ðŸš« Rejected constraint (verb detected): '{entity}'")
                return False

        return True

    def detect_switch_pattern(self, message: str, language: str = 'ru') -> Optional[Tuple[str, str]]:
        """
        Detect 'Instead of X, I want Y' patterns with validation.

        Returns:
            Tuple of (exclude_entity, desired_entity) or None
        """
        message_lower = message.lower()

        # Tightened patterns with length limits to prevent sentence capture
        # Pattern 1: Explicit "instead of" switch
        patterns = [
            r'Ð²Ð¼ÐµÑÑ‚Ð¾\s+([Ð°-ÑÑ‘\s]{3,25}?)\s+(?:Ñ…Ð¾Ñ‡Ñƒ|Ð¶ÐµÐ»Ð°ÑŽ|Ð½ÑƒÐ¶Ð½[Ð¾Ð°])\s+([Ð°-ÑÑ‘\s]{3,25}?)(?:\s*$|[.,!?])',
            # Pattern 2: "not X, but Y" - MORE RESTRICTIVE (shorter capture, Cyrillic only)
            r'Ð½Ðµ\s+([Ð°-ÑÑ‘\s]{3,20}?),?\s+Ð°\s+([Ð°-ÑÑ‘\s]{3,20}?)(?:\s*$|[.,!?])',
            # Pattern 3: English
            r'instead of\s+([a-z\s]{3,25}?),?\s+(?:I want|prefer)\s+([a-z\s]{3,25}?)(?:\s*$|[.,!?])'
        ]

        for pattern in patterns:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                exclude_entity = match.group(1).strip()
                desired_entity = match.group(2).strip()

                # CRITICAL: Validate both entities before returning
                if not self._validate_extracted_constraint(exclude_entity, language):
                    logger.warning(f"ðŸš« Invalid exclude entity in switch: '{exclude_entity}'")
                    continue

                if not self._validate_extracted_constraint(desired_entity, language):
                    logger.warning(f"ðŸš« Invalid desired entity in switch: '{desired_entity}'")
                    continue

                # Both entities passed validation
                return (exclude_entity, desired_entity)

        return None

    def normalize_time_window(self, time_expression: str, reference_date: datetime, language: str = 'ru') -> Optional[Tuple[str, str, str]]:
        """
        Normalize relative time expressions to absolute dates.

        Args:
            time_expression: "ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð°Ñ Ð½ÐµÐ´ÐµÐ»Ñ", "next week", etc.
            reference_date: Current date for calculation
            language: Language code

        Returns:
            Tuple of (start_date_iso, end_date_iso, display_str) or None
        """
        time_lower = time_expression.lower()

        # Detect "next week"
        next_week_keywords = {
            'ru': ['ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð°Ñ Ð½ÐµÐ´ÐµÐ»Ñ', 'ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ Ð½ÐµÐ´ÐµÐ»Ðµ', 'Ð½Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ Ð½ÐµÐ´ÐµÐ»Ðµ'],
            'en': ['next week'],
            'es': ['la prÃ³xima semana', 'prÃ³xima semana'],
            'he': ['×©×‘×•×¢ ×”×‘×']
        }

        keywords = next_week_keywords.get(language, next_week_keywords['en'])

        for keyword in keywords:
            if keyword in time_lower:
                # Calculate next Monday-Sunday
                days_until_monday = (7 - reference_date.weekday()) % 7
                if days_until_monday == 0:
                    days_until_monday = 7  # If today is Monday, next week starts in 7 days

                start_date = reference_date + timedelta(days=days_until_monday)
                end_date = start_date + timedelta(days=6)

                # Format display string based on language
                if language == 'ru':
                    display = f"{start_date.day}â€“{end_date.day} {self._month_name_ru(end_date.month)}"
                else:
                    display = f"{start_date.strftime('%d')}â€“{end_date.strftime('%d %B')}"

                return (
                    start_date.date().isoformat(),
                    end_date.date().isoformat(),
                    display
                )

        return None

    def _month_name_ru(self, month: int) -> str:
        """Get Russian month name (genitive case for date ranges)"""
        months = {
            1: "ÑÐ½Ð²Ð°Ñ€Ñ", 2: "Ñ„ÐµÐ²Ñ€Ð°Ð»Ñ", 3: "Ð¼Ð°Ñ€Ñ‚Ð°", 4: "Ð°Ð¿Ñ€ÐµÐ»Ñ",
            5: "Ð¼Ð°Ñ", 6: "Ð¸ÑŽÐ½Ñ", 7: "Ð¸ÑŽÐ»Ñ", 8: "Ð°Ð²Ð³ÑƒÑÑ‚Ð°",
            9: "ÑÐµÐ½Ñ‚ÑÐ±Ñ€Ñ", 10: "Ð¾ÐºÑ‚ÑÐ±Ñ€Ñ", 11: "Ð½Ð¾ÑÐ±Ñ€Ñ", 12: "Ð´ÐµÐºÐ°Ð±Ñ€Ñ"
        }
        return months.get(month, "")

    async def extract_with_llm(
        self,
        message: str,
        conversation_history: List[Dict],
        llm_client
    ) -> Dict[str, Any]:
        """
        Use LLM to extract constraints when keyword matching insufficient.

        Returns dict with:
            - desired_service: str | None
            - desired_doctor: str | None
            - excluded_doctors: List[str]
            - excluded_services: List[str]
            - confidence: float (0-1)
        """

        prompt = f"""Extract conversation constraints from this message.

Message: "{message}"

Recent conversation:
{json.dumps(conversation_history[-3:], indent=2, ensure_ascii=False)}

Extract:
1. What service does the user want? (e.g., "veneers", "cleaning")
2. What doctor do they want? (e.g., "Andrea", "Dr. Smith")
3. What doctors should be EXCLUDED? (e.g., user said "forget about Dan")
4. What services should be EXCLUDED? (e.g., user said "not fillings")

Respond ONLY with JSON:
{{
  "desired_service": "service name or null",
  "desired_doctor": "doctor name or null",
  "excluded_doctors": ["doctor1", "doctor2"],
  "excluded_services": ["service1", "service2"],
  "confidence": 0.95
}}
"""

        try:
            response = await llm_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=200
            )

            result = json.loads(response.choices[0].message.content)
            return result
        except Exception as e:
            logger.error(f"LLM constraint extraction failed: {e}")
            return {
                "desired_service": None,
                "desired_doctor": None,
                "excluded_doctors": [],
                "excluded_services": [],
                "confidence": 0.0
            }
